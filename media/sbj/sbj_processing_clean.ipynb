{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SBJ Processing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set Notebook Parameters\n",
    "\n",
    "These parameters are global\n",
    "\n",
    "Make sure to run the code block below before both pre and post processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set working directory\n",
    "p_directory = \"/Users/smarshall/Desktop/projects/media/sbj/\"\n",
    "\n",
    "# set filename -- must have file extension attached\n",
    "p_filename = \"SBJ_TEST\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pre - Processing\n",
    "- Load raw CSV from media \n",
    "- Set load locataion based on known / unknown asset types\n",
    "- Attach pipeline label data\n",
    "- Add `callback_metadata` if required\n",
    "- Split full csv into sub-csvs by loading location "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "\n",
    "# raw_media = pd.read_csv(p_directory + \"raw_media/\" + p_filename + \".csv\") # load raw media file\n",
    "raw_media = pd.read_csv(p_directory + \"raw_media/\" + \"sbj__0516\" + \".csv\") # load raw media file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set unknown asset types\n",
    "unknown_asset_types = [\"not_available\", \"unidentified\", \"na\"]\n",
    "\n",
    "# assign load location based on known / unknown asset type\n",
    "raw_media[\"load_loaction\"] = raw_media[\"asset_type\"].apply(lambda x: \"multiclass\" if x in unknown_asset_types else \"pipeline\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_data_xwalk = pd.read_csv(p_directory + \"sbj__pipeline_label_data_xwalk.csv\")\n",
    "\n",
    "merged_with_label_data = raw_media.merge(label_data_xwalk, on=\"asset_type\", how=\"left\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # attach callback metadata\n",
    "# merged_with_label_data[\"callback_metadata\"] = range(len(merged_with_label_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split into relevant csvs\n",
    "multiclass_upload = merged_with_label_data.loc[merged_with_label_data[\"load_loaction\"]==\"multiclass\"]\n",
    "pipeline_upload   = merged_with_label_data.loc[merged_with_label_data[\"load_loaction\"]==\"pipeline\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "load_loaction\n",
       "pipeline      9587\n",
       "multiclass    3590\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "merged_with_label_data.load_loaction.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "multiclass_upload.sample(frac=1).to_csv(p_directory + \"/loaded/\" + p_filename + \"__multiclass.csv\", index=False)\n",
    "pipeline_upload.sample(frac=1).to_csv(p_directory + \"/loaded/\" + p_filename + \"__pipeline.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Post - Processing\n",
    "- Load relevant CSVs\n",
    "    - Raw CSV from Media, Hive pipeline export, Hive multiclass export\n",
    "- Format Hive pipeline export\n",
    "    - Assign status conditionally based on load location, and Y/N cat job result\n",
    "    - Subset to relevant rows\n",
    "- Format Hive multiclass export\n",
    "    - Tidy Hive output status\n",
    "    - Subset to relevant rows\n",
    "- Generate deliverable table\n",
    "     - Merge Hive results back into original Media CSV to preserve Media columns\n",
    "     - De-dupe on `callback_metadata` (duplicates are introduced by merging)\n",
    "     - Remove rows with `court_reflection`\n",
    "- Export"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Relevant CSVs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "raw_media = pd.read_csv('/Users/smarshall/Desktop/projects/media/sbj/raw_media/sbj__0516.csv')\n",
    "\n",
    "pipeline_export = pd.read_csv('/Users/smarshall/Desktop/sbj__pipeline_export.csv')\n",
    "multiclass_export = pd.read_csv('/Users/smarshall/Desktop/sbj__multiclass_export.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Format Pipieline Export"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "\n",
    "# parse out binary status \n",
    "pipeline_export['binary_status'] = pipeline_export['status'].str.split('\"').str[3]\n",
    "\n",
    "# parse out multilevel status\n",
    "pipeline_export['multiclass_status'] = pipeline_export['status'].str.split('}').str[0].str.split(':').str[2]\n",
    "\n",
    "# tidy status\n",
    "pipeline_export['multiclass_status'] = pipeline_export['multiclass_status'].str.replace('\"', '')\n",
    "\n",
    "# parse out status from label data\n",
    "pipeline_export['label_data_status'] = pipeline_export['label_data'].str.split('</b>').str[1].str.split('</p>').str[0]\n",
    "\n",
    "# tidy status\n",
    "pipeline_export['label_data_status'] = pipeline_export['label_data_status'].str.replace(' ', '_').str.lower()\n",
    "\n",
    "# create final status: if binary_status is YES use label_data_status, if binary status is NO use multilevel status \n",
    "pipeline_export['delivery_status'] = np.where((pipeline_export['binary_status'] == 'yes'), \n",
    "                                               pipeline_export['label_data_status'],\n",
    "                                               pipeline_export['multiclass_status'])\n",
    "\n",
    "# subset for stack\n",
    "pipeline_for_stack = pipeline_export[['image_url', 'delivery_status']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Format Multiclass Export"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/7b/v9mp272d6r307r39j898yhnh0000gp/T/ipykernel_29988/3711670149.py:2: FutureWarning: The default value of regex will change from True to False in a future version.\n",
      "  multiclass_export['delivery_status'] = multiclass_export['status'].str.replace('\\W', '')\n"
     ]
    }
   ],
   "source": [
    "# format status \n",
    "multiclass_export['delivery_status'] = multiclass_export['status'].str.replace('\\W', '')\n",
    "\n",
    "# subset data for stack\n",
    "multiclass_for_stack = multiclass_export[['image_url', 'delivery_status']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generate Deliverable CSV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# stack datasets together \n",
    "stacked_results = pd.concat([pipeline_for_stack, multiclass_for_stack], ignore_index=True, axis=0)\n",
    "\n",
    "# rename columns for merge\n",
    "stacked_results.columns = ['stable_url', 'hive_result']\n",
    "\n",
    "# merge back into original csv from bruce using ____ as the key \n",
    "merged_results = raw_media.merge(stacked_results, on = 'stable_url', how = 'right')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove callback metadata dupes\n",
    "de_duped_merged_results = merged_results.drop_duplicates(subset = 'callback_metadata')\n",
    "\n",
    "# remove court reflection\n",
    "no_reflections = de_duped_merged_results.loc[de_duped_merged_results['hive_result'] != 'court_reflection']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>hive_result</th>\n",
       "      <th>callback_metadata</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1831</th>\n",
       "      <td>court_reflection</td>\n",
       "      <td>6666</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4757</th>\n",
       "      <td>court_reflection</td>\n",
       "      <td>12733</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7748</th>\n",
       "      <td>court_reflection</td>\n",
       "      <td>8933</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9313</th>\n",
       "      <td>court_reflection</td>\n",
       "      <td>10047</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9687</th>\n",
       "      <td>court_reflection</td>\n",
       "      <td>11961</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9869</th>\n",
       "      <td>court_reflection</td>\n",
       "      <td>6472</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12270</th>\n",
       "      <td>court_reflection</td>\n",
       "      <td>10130</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13207</th>\n",
       "      <td>court_reflection</td>\n",
       "      <td>3947</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            hive_result  callback_metadata\n",
       "1831   court_reflection               6666\n",
       "4757   court_reflection              12733\n",
       "7748   court_reflection               8933\n",
       "9313   court_reflection              10047\n",
       "9687   court_reflection              11961\n",
       "9869   court_reflection               6472\n",
       "12270  court_reflection              10130\n",
       "13207  court_reflection               3947"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# find court reflection callback metadatas \n",
    "display(de_duped_merged_results.loc[de_duped_merged_results['hive_result'] == 'court_reflection'][['hive_result', 'callback_metadata']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# subset to dlivery cols\n",
    "sbj_delivery = no_reflections.loc[:, ~no_reflections.columns.isin(['callback_metadata', 'rand', 'load_location', 'pipeline_label_data'])]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Export"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# write export\n",
    "sbj_delivery.to_csv(p_directory + \"delivered/\" + p_filename + \"__labeled.csv\", index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.16 ('myenv')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "76f9106888fdea9b9746ebdcad75a9e6c77c3a3be0693dfd991ee73141d12194"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
